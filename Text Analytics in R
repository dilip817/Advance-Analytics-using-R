# 1) Twitter

# to wrok with text stringsAsFactors=FALSE, so text is read properly
tweets <- read.csv("tweets.csv", stringsAsFactors=FALSE)
str(tweets)

tweets$negative = as.factor(tweets$Avg <= -1)
table(tweets$negative)

# Text mining package - tm
install.packages("tm")
library(tm)

# helps to use tm package
install.packages("SnowballC")

library(SnowballC)

tweets$Tweet[1]

#Corpus - Representing and computing on corpora.collections of documents containing (natural language) text
# VectorSource - interprets each element of the vector x as a document

corpus = Corpus(VectorSource(tweets$Tweet))
corpus[[1]]

corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, toupper)

corpus = tm_map(corpus, removePunctuation)

stopwords("english")[1:10]

corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))

#remove stem words (er,e etc.)

corpus = tm_map(corpus, stempDocument)

corpus = tm_map(corpus, removePunctuation)
frequencies = DocumentTermMatrix(corpus)

inspect(frequencies[1000:1005, 505:515])

findFreqTerms(frequencies, lowfreq = 20)

sparse = removeSparseTerms(frequencies, .995)

tweetsSparse = as.data.frame(as.matrix(sparse))
colnames(tweetsSparse) = make.names(colnames(tweetsSparse))

tweetsSparse$Negative = tweets$negative

library(caTools)
set.seed(123)
split = sample.split(tweetsSparse$Negative, SplitRatio=0.7)
trainSparse = subset(tweetsSparse, split ==TRUE )
testSparse = subset(tweetsSparse, split ==FALSE )

library(rpart)
library(rpart.plot)

tweetCART = rpart(Negative ~ ., data = trainSparse, method = "class")
prp(tweetCART)

predictCART = predict(tweetCART, newdata = testSparse, type="class")
table(testSparse$Negative, predictCART)

table(testSparse$Negative)

library(randomForest)
set.seed(123)
tweetRF = randomForest(Negative ~ ., data = trainSparse)
predictRF = predict(tweetRF, newdata=testSparse)
table(testSparse$Negative, predictRF)

# Predictive coding
emails = read.csv("energy_bids.csv", stringsAsFactors = FALSE)
str(emails)

emails$email[1]
emails$responsive[1]

emails$email[1]

table(emails$responsive)
library(tm)

corpus = Corpus(VectorSource(emails$email))
strwrap(corpus[[1]])

corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, stopwords("english"))
corpus = tm_map(corpus, stemDocument)

strwrap(corpus[[1]])

dtm = DocumentTermMatrix(corpus)

dtm = removeSparseTerms(dtm, 0.97)

labeledTerms = as.data.frame(as.matrix(dtm))
labeledTerms$Responsive = emails$responsive

str(labeledTerms)

library(caTools)
set.seed(144)

spl = sample.split(labeledTerms$Responsive, 0.7)

train = subset(labeledTerms, spl ==TRUE)
test = subset(labeledTerms, spl ==FALSE)

library(rpart)
library(rpart.plot)

emailPART = rpart(Responsive ~., data = train, method = "class")
prp(emailPART)

pred = predict(emailPART, newdata = test)
pred[1:10,]

pred.prob = pred[,2]
table(test$Responsive, pred.prob>= 0.5)

table(test$Responsive)

library(ROCR)
predROCR = prediction(pred.prob, test$Responsive)

perfROCR = performance(predROCR, "tpr", "fpr")

plot(perfROCR, colorize = TRUE)
performance(predROCR, "auc")@y.values



